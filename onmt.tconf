global {
  
  # GLOBAL/PREPROCESSING CONFIGURATIONS
  working_dir="/export/b18/shuoyangd/projects/tape4nmt"

  SRC=zh
  TRG=en
  trg_lang=English
  Ratio=1
  MaxLen=80

  bpe_operations=49500

  njobs=50
  resource_flags="-l 'mem_free=2g,ram_free=2g'"
  action_flags="-m ae -M dings@jhu.edu"

  train_data=(
    side:
      src="../data/corpus.sents.zh.10000"
      trg="../data/corpus.sents.en.10000"
  )

  dev_data=(
    side:
      src="../data/eval05.zh"
      trg="../data/eval05.en"
  )

  devtest_data=(
    side:
      src="../data/eval08.zh"
      trg="../data/eval08.en"
  )

  wrap_template="../data/eval08.zh"

  sgm_dev=""
  sgm_devtest="true"

  multi_bleu="true"
  nist_bleu="true"

  # TRAINING CONFIGURATIONS
  # all default is consistent with nematus
  train_train_from="" # if there is a previous model to start with
  train_train_from_state_dict="" # if there is a previous dict to start with
  train_start_epoch="" # if trained for certain amount of epochs previously
  
  train_layers="2"
  train_rnn_size="1024"
  train_word_vec_size="300"
  # train_brnn="true" # deprecated!
  train_batch_size="80"
  train_epochs="20" 
  train_optim="adadelta"
  train_dropout="0.2" # implementation may not be consistent with nematus
  train_learning_rate="1.0"
  train_pre_word_vecs_enc=""
  train_pre_word_vecs_dec=""
  train_pre_word_vecs_enc_features_prefix=""
  train_enc_fix=""
  train_encoder_type="brnn"

  # TEST CONFIGURATIONS
  test_model_selection_strategy="ppl"
}
